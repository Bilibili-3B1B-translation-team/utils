[Script Info]
; Script generated by Aegisub 3.2.1
; http://www.aegisub.org/
Title: Default Aegisub file
ScriptType: v4.00+
WrapStyle: 0
ScaledBorderAndShadow: yes
YCbCr Matrix: TV.709
PlayResX: 1920
PlayResY: 1200

[Aegisub Project Garbage]
Audio File: audio.160.mp3
Video File: CLT.1080.mp4
Video AR Mode: 4
Video AR Value: 1.600000
Video Zoom Percent: 1.140625
Scroll Position: 222
Active Line: 250
Video Position: 27328

[V4+ Styles]
Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding
Style: Default,Arial,48,&H00FFFFFF,&H000000FF,&H00000000,&H00000000,0,0,0,0,100,100,0,0,1,2,2,2,10,10,10,1
Style: ENG,Inter Medium,50,&H00FFFFFF,&H00000000,&H00000000,&H00000000,-1,0,0,0,94,100,0,0,1,3,3,2,15,15,20,1
Style: CHN,MonyharOS Sans SC Medium,66,&H00FFFFFF,&H0055060A,&H0055060A,&H00000000,-1,0,0,0,98,100,0,0,1,4.5,3,2,15,15,75,1
Style: Staff,MonyharOS Sans SC Medium,50,&H00FFFFFF,&H0055060A,&H00AE9B5F,&H00000000,0,0,0,0,100,100,0,0,1,3,3,8,10,10,30,1

[Events]
Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text
Dialogue: 0,0:00:00.00,0:00:01.50,ENG,,0,0,0,,This is a Galton Board.
Dialogue: 0,0:00:00.00,0:00:01.50,CHN,,0,0,0,,
Dialogue: 0,0:00:02.46,0:00:04.92,ENG,,0,0,0,,Maybe you've seen one before. It's a popular demonstration
Dialogue: 0,0:00:02.46,0:00:04.92,CHN,,0,0,0,,
Dialogue: 0,0:00:04.98,0:00:08.12,ENG,,0,0,0,,of how even when a single event is chaotic and random,
Dialogue: 0,0:00:04.98,0:00:08.12,CHN,,0,0,0,,
Dialogue: 0,0:00:08.12,0:00:10.24,ENG,,0,0,0,,with an effectively unknowable outcome,
Dialogue: 0,0:00:08.12,0:00:10.24,CHN,,0,0,0,,
Dialogue: 0,0:00:10.44,0:00:14.26,ENG,,0,0,0,,it's still possible to make precise statements about a large number of events,
Dialogue: 0,0:00:10.44,0:00:14.26,CHN,,0,0,0,,
Dialogue: 0,0:00:14.26,0:00:18.36,ENG,,0,0,0,,namely how the relative proportions for many different outcomes are distributed.
Dialogue: 0,0:00:14.26,0:00:18.36,CHN,,0,0,0,,
Dialogue: 0,0:00:20.64,0:00:23.82,ENG,,0,0,0,,More specifically, the Galton board illustrates one of the most prominent
Dialogue: 0,0:00:20.64,0:00:23.82,CHN,,0,0,0,,
Dialogue: 0,0:00:23.82,0:00:27.30,ENG,,0,0,0,,distributions in all of probability, known as the Normal distribution,
Dialogue: 0,0:00:23.82,0:00:27.30,CHN,,0,0,0,,
Dialogue: 0,0:00:27.30,0:00:32.26,ENG,,0,0,0,,more colloquially known as a Bell curve, and also called a Gaussian distribution.
Dialogue: 0,0:00:27.30,0:00:32.26,CHN,,0,0,0,,
Dialogue: 0,0:00:32.26,0:00:35.46,ENG,,0,0,0,,There's a very specific function to describe this distribution.
Dialogue: 0,0:00:32.26,0:00:35.46,CHN,,0,0,0,,
Dialogue: 0,0:00:35.46,0:00:37.16,ENG,,0,0,0,,Very pretty. We'll get into it later,
Dialogue: 0,0:00:35.46,0:00:37.16,CHN,,0,0,0,,
Dialogue: 0,0:00:37.16,0:00:40.38,ENG,,0,0,0,,but right now, I just want to emphasize how the normal distribution is,
Dialogue: 0,0:00:37.16,0:00:40.38,CHN,,0,0,0,,
Dialogue: 0,0:00:40.38,0:00:45.18,ENG,,0,0,0,,as the name suggests, very common. It shows up in a lot of seemingly unrelated contexts.
Dialogue: 0,0:00:40.38,0:00:45.18,CHN,,0,0,0,,
Dialogue: 0,0:00:45.84,0:00:49.34,ENG,,0,0,0,,If you were to take a large number of people who sit in a similar demographic
Dialogue: 0,0:00:45.84,0:00:49.34,CHN,,0,0,0,,
Dialogue: 0,0:00:49.34,0:00:53.44,ENG,,0,0,0,,and plot their heights, those heights tend to follow a normal distribution.
Dialogue: 0,0:00:49.34,0:00:53.44,CHN,,0,0,0,,
Dialogue: 0,0:00:53.44,0:00:56.80,ENG,,0,0,0,,If you look at a large swath of very big natural numbers
Dialogue: 0,0:00:53.44,0:00:56.80,CHN,,0,0,0,,
Dialogue: 0,0:00:56.80,0:01:01.18,ENG,,0,0,0,,and you ask how many distinct prime factors does each one of those numbers have,
Dialogue: 0,0:00:56.80,0:01:01.18,CHN,,0,0,0,,
Dialogue: 0,0:01:01.18,0:01:04.98,ENG,,0,0,0,,the answers will very closely track with a certain normal distribution.
Dialogue: 0,0:01:01.18,0:01:04.98,CHN,,0,0,0,,
Dialogue: 0,0:01:04.98,0:01:09.34,ENG,,0,0,0,,Now, our topic for today is one of the crown jewels in all of probability theory.
Dialogue: 0,0:01:04.98,0:01:09.34,CHN,,0,0,0,,
Dialogue: 0,0:01:09.34,0:01:13.92,ENG,,0,0,0,,It's one of the key facts that explains why this distribution is as common as it is,
Dialogue: 0,0:01:09.34,0:01:13.92,CHN,,0,0,0,,
Dialogue: 0,0:01:13.92,0:01:16.24,ENG,,0,0,0,,known as the Central Limit Theorem.
Dialogue: 0,0:01:13.92,0:01:16.24,CHN,,0,0,0,,
Dialogue: 0,0:01:16.24,0:01:18.66,ENG,,0,0,0,,This lesson is meant to go back to the basics,
Dialogue: 0,0:01:16.24,0:01:18.66,CHN,,0,0,0,,
Dialogue: 0,0:01:18.66,0:01:21.78,ENG,,0,0,0,,giving you the fundamentals on what the Central Limit Theorem is saying,
Dialogue: 0,0:01:18.66,0:01:21.78,CHN,,0,0,0,,
Dialogue: 0,0:01:21.78,0:01:24.72,ENG,,0,0,0,,what normal distributions are, and I want to assume minimal background.
Dialogue: 0,0:01:21.78,0:01:24.72,CHN,,0,0,0,,
Dialogue: 0,0:01:24.72,0:01:28.08,ENG,,0,0,0,,We're going to go decently deep into it, but after this,
Dialogue: 0,0:01:24.72,0:01:28.08,CHN,,0,0,0,,
Dialogue: 0,0:01:28.08,0:01:31.30,ENG,,0,0,0,,I'd still like to go deeper and explain why the theorem is true,
Dialogue: 0,0:01:28.08,0:01:31.30,CHN,,0,0,0,,
Dialogue: 0,0:01:31.30,0:01:34.18,ENG,,0,0,0,,why the function underlying the normal distribution
Dialogue: 0,0:01:31.30,0:01:34.18,CHN,,0,0,0,,
Dialogue: 0,0:01:34.18,0:01:36.70,ENG,,0,0,0,,has the very specific form that it does,
Dialogue: 0,0:01:34.18,0:01:36.70,CHN,,0,0,0,,
Dialogue: 0,0:01:36.70,0:01:39.14,ENG,,0,0,0,,why that formula has a pi in it,
Dialogue: 0,0:01:36.70,0:01:39.14,CHN,,0,0,0,,
Dialogue: 0,0:01:39.14,0:01:40.68,ENG,,0,0,0,,and, most fun,
Dialogue: 0,0:01:39.14,0:01:40.68,CHN,,0,0,0,,
Dialogue: 0,0:01:40.68,0:01:45.60,ENG,,0,0,0,,why those last two facts are actually more related than a lot of traditional explanations would suggest.
Dialogue: 0,0:01:40.68,0:01:45.60,CHN,,0,0,0,,
Dialogue: 0,0:01:46.38,0:01:51.00,ENG,,0,0,0,,That second lesson is also meant to be the follow on to the convolutions video that I promised.
Dialogue: 0,0:01:46.38,0:01:51.00,CHN,,0,0,0,,
Dialogue: 0,0:01:51.00,0:01:53.26,ENG,,0,0,0,,So, there's a lot of interrelated topics here.
Dialogue: 0,0:01:51.00,0:01:53.26,CHN,,0,0,0,,
Dialogue: 0,0:01:53.26,0:01:55.18,ENG,,0,0,0,,But right now, back to the fundamentals.
Dialogue: 0,0:01:53.26,0:01:55.18,CHN,,0,0,0,,
Dialogue: 0,0:01:55.18,0:01:59.28,ENG,,0,0,0,,I'd like to kick things off with an overly simplified model of the Galton board.
Dialogue: 0,0:01:55.18,0:01:59.28,CHN,,0,0,0,,
Dialogue: 0,0:02:01.02,0:02:05.60,ENG,,0,0,0,,In this model, we will assume that each ball falls directly onto a certain central peg
Dialogue: 0,0:02:01.02,0:02:05.60,CHN,,0,0,0,,
Dialogue: 0,0:02:05.60,0:02:09.66,ENG,,0,0,0,,and then it has a 50 - 50 probability of bouncing to the left or to the right,
Dialogue: 0,0:02:05.60,0:02:09.66,CHN,,0,0,0,,
Dialogue: 0,0:02:09.66,0:02:14.40,ENG,,0,0,0,,and we'll think of each of those outcomes as either adding one or subtracting one from its position.
Dialogue: 0,0:02:09.66,0:02:14.40,CHN,,0,0,0,,
Dialogue: 0,0:02:14.40,0:02:18.96,ENG,,0,0,0,,Once one of those is chosen, we make the highly unrealistic assumption that
Dialogue: 0,0:02:14.40,0:02:18.96,CHN,,0,0,0,,
Dialogue: 0,0:02:18.96,0:02:23.22,ENG,,0,0,0,,it happens to land dead on in the middle of the peg adjacent below it, where again,
Dialogue: 0,0:02:18.96,0:02:23.22,CHN,,0,0,0,,
Dialogue: 0,0:02:23.22,0:02:27.12,ENG,,0,0,0,,it'll be faced with the same 50 - 50 choice of bouncing to the left or to the right.
Dialogue: 0,0:02:23.22,0:02:27.12,CHN,,0,0,0,,
Dialogue: 0,0:02:27.12,0:02:30.64,ENG,,0,0,0,,For the one I'm showing on screen, there are five different rows of pegs.
Dialogue: 0,0:02:27.12,0:02:30.64,CHN,,0,0,0,,
Dialogue: 0,0:02:30.64,0:02:35.64,ENG,,0,0,0,,So our little hopping ball makes five different random choices between plus one and minus one,
Dialogue: 0,0:02:30.64,0:02:35.64,CHN,,0,0,0,,
Dialogue: 0,0:02:35.64,0:02:40.46,ENG,,0,0,0,,and we can think of its final position as basically being the sum of all of those different numbers.
Dialogue: 0,0:02:35.64,0:02:40.46,CHN,,0,0,0,,
Dialogue: 0,0:02:40.46,0:02:42.82,ENG,,0,0,0,,Which in this case happens to be one,
Dialogue: 0,0:02:40.46,0:02:42.82,CHN,,0,0,0,,
Dialogue: 0,0:02:42.82,0:02:46.44,ENG,,0,0,0,,and we might label all of the different buckets with the sum that they represent.
Dialogue: 0,0:02:42.82,0:02:46.44,CHN,,0,0,0,,
Dialogue: 0,0:02:46.44,0:02:51.06,ENG,,0,0,0,,As we repeat this, we're looking at different possible sums for those five random numbers.
Dialogue: 0,0:02:46.44,0:02:51.06,CHN,,0,0,0,,
Dialogue: 0,0:02:52.74,0:02:58.10,ENG,,0,0,0,,And for those of you who are inclined to complain that this is a highly unrealistic model for the true Galton board
Dialogue: 0,0:02:52.74,0:02:58.10,CHN,,0,0,0,,
Dialogue: 0,0:02:58.10,0:03:01.80,ENG,,0,0,0,,let me emphasize - the goal right now is not to accurately model physics,
Dialogue: 0,0:02:58.10,0:03:01.80,CHN,,0,0,0,,
Dialogue: 0,0:03:01.80,0:03:05.76,ENG,,0,0,0,,the goal is to give a simple example to illustrate the central limit theorem,
Dialogue: 0,0:03:01.80,0:03:05.76,CHN,,0,0,0,,
Dialogue: 0,0:03:05.76,0:03:10.14,ENG,,0,0,0,,and for that, idealized though this might be, it actually gives us a really good example.
Dialogue: 0,0:03:05.76,0:03:10.14,CHN,,0,0,0,,
Dialogue: 0,0:03:10.14,0:03:12.44,ENG,,0,0,0,,If we let many different balls fall,
Dialogue: 0,0:03:10.14,0:03:12.44,CHN,,0,0,0,,
Dialogue: 0,0:03:12.44,0:03:17.20,ENG,,0,0,0,,making yet another unrealistic assumption that they don't influence each other, as if they're all ghosts,
Dialogue: 0,0:03:12.44,0:03:17.20,CHN,,0,0,0,,
Dialogue: 0,0:03:17.20,0:03:20.02,ENG,,0,0,0,,then the number of balls that fall into each different bucket
Dialogue: 0,0:03:17.20,0:03:20.02,CHN,,0,0,0,,
Dialogue: 0,0:03:20.02,0:03:23.46,ENG,,0,0,0,,gives us some loose sense for how likely each one of those buckets is.
Dialogue: 0,0:03:20.02,0:03:23.46,CHN,,0,0,0,,
Dialogue: 0,0:03:23.46,0:03:27.54,ENG,,0,0,0,,In this example the numbers are simple enough that it's not too hard to explicitly
Dialogue: 0,0:03:23.46,0:03:27.54,CHN,,0,0,0,,
Dialogue: 0,0:03:27.54,0:03:30.22,ENG,,0,0,0,,calculate what the probability is for falling into each bucket.
Dialogue: 0,0:03:27.54,0:03:30.22,CHN,,0,0,0,,
Dialogue: 0,0:03:30.22,0:03:34.02,ENG,,0,0,0,,If you do want to think that through, you'll find it very reminiscent of Pascal's triangle,
Dialogue: 0,0:03:30.22,0:03:34.02,CHN,,0,0,0,,
Dialogue: 0,0:03:34.02,0:03:38.34,ENG,,0,0,0,,but the neat thing about our theorem is how far it goes beyond the simple examples.
Dialogue: 0,0:03:34.02,0:03:38.34,CHN,,0,0,0,,
Dialogue: 0,0:03:38.34,0:03:41.64,ENG,,0,0,0,,So, to start off at least, rather than making explicit calculations,
Dialogue: 0,0:03:38.34,0:03:41.64,CHN,,0,0,0,,
Dialogue: 0,0:03:41.64,0:03:44.52,ENG,,0,0,0,,let's just simulating things by running a large number of samples
Dialogue: 0,0:03:41.64,0:03:44.52,CHN,,0,0,0,,
Dialogue: 0,0:03:44.52,0:03:47.54,ENG,,0,0,0,,and letting the total number of results in each different outcome
Dialogue: 0,0:03:44.52,0:03:47.54,CHN,,0,0,0,,
Dialogue: 0,0:03:47.54,0:03:49.64,ENG,,0,0,0,,give us some sense for what that distribution looks like.
Dialogue: 0,0:03:47.54,0:03:49.64,CHN,,0,0,0,,
Dialogue: 0,0:03:50.36,0:03:52.72,ENG,,0,0,0,,As I said, the one on screen has five rows,
Dialogue: 0,0:03:50.36,0:03:52.72,CHN,,0,0,0,,
Dialogue: 0,0:03:52.72,0:03:56.42,ENG,,0,0,0,,so each sum that we're considering includes only five numbers.
Dialogue: 0,0:03:52.72,0:03:56.42,CHN,,0,0,0,,
Dialogue: 0,0:03:56.42,0:04:01.44,ENG,,0,0,0,,The basic idea of the central limit theorem is that if you increase the size of that sum,
Dialogue: 0,0:03:56.42,0:04:01.44,CHN,,0,0,0,,
Dialogue: 0,0:04:01.44,0:04:06.88,ENG,,0,0,0,,for example, here that would mean increasing the number of rows of pegs for each ball to bounce off
Dialogue: 0,0:04:01.44,0:04:06.88,CHN,,0,0,0,,
Dialogue: 0,0:04:06.88,0:04:11.26,ENG,,0,0,0,,then the distribution that describes where that sum is going to fall
Dialogue: 0,0:04:06.88,0:04:11.26,CHN,,0,0,0,,
Dialogue: 0,0:04:11.26,0:04:13.62,ENG,,0,0,0,,looks more and more like a bell curve.
Dialogue: 0,0:04:11.26,0:04:13.62,CHN,,0,0,0,,
Dialogue: 0,0:04:15.30,0:04:18.48,ENG,,0,0,0,,Here, it's actually worth taking a moment to write down that general idea.
Dialogue: 0,0:04:15.30,0:04:18.48,CHN,,0,0,0,,
Dialogue: 0,0:04:19.26,0:04:24.24,ENG,,0,0,0,,The setup is that we have a random variable and that's basically shorthand for a random
Dialogue: 0,0:04:19.26,0:04:24.24,CHN,,0,0,0,,
Dialogue: 0,0:04:24.24,0:04:28.38,ENG,,0,0,0,,process where each outcome of that process is associated with some number.
Dialogue: 0,0:04:24.24,0:04:28.38,CHN,,0,0,0,,
Dialogue: 0,0:04:28.38,0:04:30.00,ENG,,0,0,0,,We'll call that random number X.
Dialogue: 0,0:04:28.38,0:04:30.00,CHN,,0,0,0,,
Dialogue: 0,0:04:30.00,0:04:34.56,ENG,,0,0,0,,For example, each bounce off the peg is a random process modeled with two outcomes.
Dialogue: 0,0:04:30.00,0:04:34.56,CHN,,0,0,0,,
Dialogue: 0,0:04:34.56,0:04:37.80,ENG,,0,0,0,,Those outcomes are associated with the numbers negative one and positive one.
Dialogue: 0,0:04:34.56,0:04:37.80,CHN,,0,0,0,,
Dialogue: 0,0:04:38.34,0:04:41.32,ENG,,0,0,0,,Another example of a random variable would be rolling a die,
Dialogue: 0,0:04:38.34,0:04:41.32,CHN,,0,0,0,,
Dialogue: 0,0:04:41.32,0:04:45.10,ENG,,0,0,0,,where you have six different outcomes each one associated with a number.
Dialogue: 0,0:04:41.32,0:04:45.10,CHN,,0,0,0,,
Dialogue: 0,0:04:45.10,0:04:50.56,ENG,,0,0,0,,What we're doing is taking multiple different samples of that variable and adding them all together.
Dialogue: 0,0:04:45.10,0:04:50.56,CHN,,0,0,0,,
Dialogue: 0,0:04:50.56,0:04:53.34,ENG,,0,0,0,,On our Galton board, that looks like letting the ball bounce off
Dialogue: 0,0:04:50.56,0:04:53.34,CHN,,0,0,0,,
Dialogue: 0,0:04:53.34,0:04:56.16,ENG,,0,0,0,,multiple different pegs on its way down to the bottom, 
Dialogue: 0,0:04:53.34,0:04:56.16,CHN,,0,0,0,,
Dialogue: 0,0:04:56.60,0:04:58.52,ENG,,0,0,0,,and in the case of a die, you might imagine
Dialogue: 0,0:04:56.60,0:04:58.52,CHN,,0,0,0,,
Dialogue: 0,0:04:58.24,0:05:00.90,ENG,,0,0,0,,rolling many different dice and adding up the results.
Dialogue: 0,0:04:58.24,0:05:00.90,CHN,,0,0,0,,
Dialogue: 0,0:05:00.90,0:05:03.16,ENG,,0,0,0,,The claim of the central limit theorem
Dialogue: 0,0:05:00.90,0:05:03.16,CHN,,0,0,0,,
Dialogue: 0,0:05:03.16,0:05:06.62,ENG,,0,0,0,,is that as you let the size of that sum get bigger and bigger,
Dialogue: 0,0:05:03.16,0:05:06.62,CHN,,0,0,0,,
Dialogue: 0,0:05:06.62,0:05:11.66,ENG,,0,0,0,,then the distribution of that sum, how likely it is to fall into different possible values,
Dialogue: 0,0:05:06.62,0:05:11.66,CHN,,0,0,0,,
Dialogue: 0,0:05:11.66,0:05:14.06,ENG,,0,0,0,,will look more and more like a bell curve.
Dialogue: 0,0:05:11.66,0:05:14.06,CHN,,0,0,0,,
Dialogue: 0,0:05:15.28,0:05:17.28,ENG,,0,0,0,,That's it, that is the general idea.
Dialogue: 0,0:05:15.28,0:05:17.28,CHN,,0,0,0,,
Dialogue: 0,0:05:17.28,0:05:21.78,ENG,,0,0,0,,Over the course of this lesson, our job is to make that statement more quantitative.
Dialogue: 0,0:05:17.28,0:05:21.78,CHN,,0,0,0,,
Dialogue: 0,0:05:21.78,0:05:26.52,ENG,,0,0,0,,We're going to put some numbers to it, put some formulas to it, show how you can use it to make predictions.
Dialogue: 0,0:05:21.78,0:05:26.52,CHN,,0,0,0,,
Dialogue: 0,0:05:27.36,0:05:31.56,ENG,,0,0,0,,For example, here's the kind of question I want you to be able to answer by the end of this video:
Dialogue: 0,0:05:27.36,0:05:31.56,CHN,,0,0,0,,
Dialogue: 0,0:05:32.16,0:05:35.76,ENG,,0,0,0,,suppose you roll the die 100 times, and you added together the results.
Dialogue: 0,0:05:32.16,0:05:35.76,CHN,,0,0,0,,
Dialogue: 0,0:05:36.48,0:05:42.32,ENG,,0,0,0,,Could you find a range of values such that you're 95% sure that the sum will fall within that range.
Dialogue: 0,0:05:36.48,0:05:42.32,CHN,,0,0,0,,
Dialogue: 0,0:05:42.32,0:05:46.56,ENG,,0,0,0,,Or maybe I should say, find the smallest possible range of values such that this is true.
Dialogue: 0,0:05:42.32,0:05:46.56,CHN,,0,0,0,,
Dialogue: 0,0:05:47.28,0:05:52.18,ENG,,0,0,0,,The neat thing is, you'll be able to answer this question whether it's a fair die or if it's a weighted die.
Dialogue: 0,0:05:47.28,0:05:52.18,CHN,,0,0,0,,
Dialogue: 0,0:05:53.52,0:05:57.68,ENG,,0,0,0,,Now, let me say at the top that this theorem has three different assumptions that go into it.
Dialogue: 0,0:05:53.52,0:05:57.68,CHN,,0,0,0,,
Dialogue: 0,0:05:57.68,0:06:00.34,ENG,,0,0,0,,Three things that have to be true before the theorem follows
Dialogue: 0,0:05:57.68,0:06:00.34,CHN,,0,0,0,,
Dialogue: 0,0:06:00.34,0:06:03.98,ENG,,0,0,0,,and I'm actually not going to tell you what they are until the very end of the video.
Dialogue: 0,0:06:00.34,0:06:03.98,CHN,,0,0,0,,
Dialogue: 0,0:06:03.98,0:06:07.74,ENG,,0,0,0,,Instead, I want you to keep your eye out and see if you can notice and maybe predict
Dialogue: 0,0:06:03.98,0:06:07.74,CHN,,0,0,0,,
Dialogue: 0,0:06:07.74,0:06:09.70,ENG,,0,0,0,,what those three assumptions are going to be.
Dialogue: 0,0:06:07.74,0:06:09.70,CHN,,0,0,0,,
Dialogue: 0,0:06:10.48,0:06:13.82,ENG,,0,0,0,,As a next step to better illustrate just how general this theorem is,
Dialogue: 0,0:06:10.48,0:06:13.82,CHN,,0,0,0,,
Dialogue: 0,0:06:13.82,0:06:17.58,ENG,,0,0,0,,I want to run a couple more simulations for you focused on the dice example.
Dialogue: 0,0:06:13.82,0:06:17.58,CHN,,0,0,0,,
Dialogue: 0,0:06:20.88,0:06:25.54,ENG,,0,0,0,,Usually, if you think of rolling a die, you think of the six outcomes as being equally probable,
Dialogue: 0,0:06:20.88,0:06:25.54,CHN,,0,0,0,,
Dialogue: 0,0:06:25.54,0:06:27.70,ENG,,0,0,0,,but the theorem actually doesn't care about that.
Dialogue: 0,0:06:25.54,0:06:27.70,CHN,,0,0,0,,
Dialogue: 0,0:06:27.70,0:06:29.60,ENG,,0,0,0,,We could start with a weighted die
Dialogue: 0,0:06:27.70,0:06:29.60,CHN,,0,0,0,,
Dialogue: 0,0:06:29.60,0:06:32.86,ENG,,0,0,0,,something with a non-trivial distribution across the outcomes
Dialogue: 0,0:06:29.60,0:06:32.86,CHN,,0,0,0,,
Dialogue: 0,0:06:32.86,0:06:34.66,ENG,,0,0,0,,and the core idea still holds,
Dialogue: 0,0:06:32.86,0:06:34.66,CHN,,0,0,0,,
Dialogue: 0,0:06:34.66,0:06:37.44,ENG,,0,0,0,,for the simulation what will do is take some distribution,
Dialogue: 0,0:06:34.66,0:06:37.44,CHN,,0,0,0,,
Dialogue: 0,0:06:37.44,0:06:40.24,ENG,,0,0,0,,like this one that is skewed towards lower values.
Dialogue: 0,0:06:37.44,0:06:40.24,CHN,,0,0,0,,
Dialogue: 0,0:06:40.24,0:06:43.80,ENG,,0,0,0,,I'm going to take 10 distinct samples from that distribution,
Dialogue: 0,0:06:40.24,0:06:43.80,CHN,,0,0,0,,
Dialogue: 0,0:06:43.80,0:06:47.52,ENG,,0,0,0,,and then I'll record the sum of that sample on the plot, on the bottom.
Dialogue: 0,0:06:43.80,0:06:47.52,CHN,,0,0,0,,
Dialogue: 0,0:06:48.36,0:06:50.78,ENG,,0,0,0,,Then I'm going to do this many many different times.
Dialogue: 0,0:06:48.36,0:06:50.78,CHN,,0,0,0,,
Dialogue: 0,0:06:50.78,0:06:52.88,ENG,,0,0,0,,Always with the sum of size 10
Dialogue: 0,0:06:50.78,0:06:52.88,CHN,,0,0,0,,
Dialogue: 0,0:06:52.88,0:06:56.72,ENG,,0,0,0,,but keep track of where those sums ended up to give us a sense of the distribution.
Dialogue: 0,0:06:52.88,0:06:56.72,CHN,,0,0,0,,
Dialogue: 0,0:06:59.46,0:07:04.74,ENG,,0,0,0,,And in fact, let me rescale the y direction to give us room to run an even larger number of samples,
Dialogue: 0,0:06:59.46,0:07:04.74,CHN,,0,0,0,,
Dialogue: 0,0:07:04.74,0:07:07.44,ENG,,0,0,0,,and I'll let it go all the way up to a couple thousand
Dialogue: 0,0:07:04.74,0:07:07.44,CHN,,0,0,0,,
Dialogue: 0,0:07:07.44,0:07:10.82,ENG,,0,0,0,,and as it does, you'll notice that the shape that starts to emerge
Dialogue: 0,0:07:07.44,0:07:10.82,CHN,,0,0,0,,
Dialogue: 0,0:07:10.82,0:07:12.62,ENG,,0,0,0,,looks like a bell curve.
Dialogue: 0,0:07:10.82,0:07:12.62,CHN,,0,0,0,,
Dialogue: 0,0:07:12.62,0:07:16.50,ENG,,0,0,0,,Maybe if you squint your eyes you can see it skews a tiny bit to the left,
Dialogue: 0,0:07:12.62,0:07:16.50,CHN,,0,0,0,,
Dialogue: 0,0:07:16.50,0:07:21.18,ENG,,0,0,0,,but it's neat that something so symmetric emerged from a starting point that was so asymmetric.
Dialogue: 0,0:07:16.50,0:07:21.18,CHN,,0,0,0,,
Dialogue: 0,0:07:21.18,0:07:24.00,ENG,,0,0,0,,To better illustrate what the central limit theorem is all about,
Dialogue: 0,0:07:21.18,0:07:24.00,CHN,,0,0,0,,
Dialogue: 0,0:07:24.00,0:07:26.96,ENG,,0,0,0,,let me run four of these simulations in parallel.
Dialogue: 0,0:07:24.00,0:07:26.96,CHN,,0,0,0,,
Dialogue: 0,0:07:26.96,0:07:31.00,ENG,,0,0,0,,Where on the upper left I'm doing it - we're only adding two dice at a time.
Dialogue: 0,0:07:26.96,0:07:31.00,CHN,,0,0,0,,
Dialogue: 0,0:07:31.00,0:07:34.26,ENG,,0,0,0,,On the upper right, we're doing it where we're adding five dice at a time,
Dialogue: 0,0:07:31.00,0:07:34.26,CHN,,0,0,0,,
Dialogue: 0,0:07:34.26,0:07:38.22,ENG,,0,0,0,,the lower left is the one that we just saw, adding 10 dice at a time
Dialogue: 0,0:07:34.26,0:07:38.22,CHN,,0,0,0,,
Dialogue: 0,0:07:38.22,0:07:41.04,ENG,,0,0,0,,and then we'll do another one with a bigger sum, 15 at a time.
Dialogue: 0,0:07:38.22,0:07:41.04,CHN,,0,0,0,,
Dialogue: 0,0:07:42.18,0:07:45.04,ENG,,0,0,0,,Notice how on the upper left when we're just adding two dice,
Dialogue: 0,0:07:42.18,0:07:45.04,CHN,,0,0,0,,
Dialogue: 0,0:07:45.04,0:07:48.12,ENG,,0,0,0,,the resulting distribution doesn't really look like a bell curve,
Dialogue: 0,0:07:45.04,0:07:48.12,CHN,,0,0,0,,
Dialogue: 0,0:07:48.12,0:07:52.00,ENG,,0,0,0,,it looks a lot more reminiscent of the one we started with - skewed towards the left.
Dialogue: 0,0:07:48.12,0:07:52.00,CHN,,0,0,0,,
Dialogue: 0,0:07:52.68,0:07:55.38,ENG,,0,0,0,,But as we allow for more and more dice in each sum,
Dialogue: 0,0:07:52.68,0:07:55.38,CHN,,0,0,0,,
Dialogue: 0,0:07:55.38,0:07:59.94,ENG,,0,0,0,,the resulting shape that comes up in these distributions looks more and more symmetric.
Dialogue: 0,0:07:55.38,0:07:59.94,CHN,,0,0,0,,
Dialogue: 0,0:07:59.94,0:08:04.50,ENG,,0,0,0,,It has the lump in the middle and fade towards the tail shape of a bell curve.
Dialogue: 0,0:07:59.94,0:08:04.50,CHN,,0,0,0,,
Dialogue: 0,0:08:06.98,0:08:10.62,ENG,,0,0,0,,Let me emphasize again, you can start with any different distribution.
Dialogue: 0,0:08:06.98,0:08:10.62,CHN,,0,0,0,,
Dialogue: 0,0:08:10.62,0:08:15.10,ENG,,0,0,0,,Here I'll run it again but where most of the probability is tied up in the numbers 1 and 6
Dialogue: 0,0:08:10.62,0:08:15.10,CHN,,0,0,0,,
Dialogue: 0,0:08:15.10,0:08:17.68,ENG,,0,0,0,,with very low probability for the mid values.
Dialogue: 0,0:08:15.10,0:08:17.68,CHN,,0,0,0,,
Dialogue: 0,0:08:17.68,0:08:22.02,ENG,,0,0,0,,Despite completely changing the distribution for an individual roll of the die,
Dialogue: 0,0:08:17.68,0:08:22.02,CHN,,0,0,0,,
Dialogue: 0,0:08:22.02,0:08:26.70,ENG,,0,0,0,,it's still the case that a bell curve shape will emerge as we consider the different sums.
Dialogue: 0,0:08:22.02,0:08:26.70,CHN,,0,0,0,,
Dialogue: 0,0:08:26.70,0:08:30.14,ENG,,0,0,0,,Illustrating things with a simulation like this is very fun
Dialogue: 0,0:08:26.70,0:08:30.14,CHN,,0,0,0,,
Dialogue: 0,0:08:30.14,0:08:32.64,ENG,,0,0,0,,and it's kind of neat to see order emerge from chaos
Dialogue: 0,0:08:30.14,0:08:32.64,CHN,,0,0,0,,
Dialogue: 0,0:08:32.64,0:08:36.16,ENG,,0,0,0,,but it also feels a little imprecise. Like in this case.
Dialogue: 0,0:08:32.64,0:08:36.16,CHN,,0,0,0,,
Dialogue: 0,0:08:36.16,0:08:41.10,ENG,,0,0,0,,When I cut off the simulation at 3000 samples, even though it kind of looks like a bell curve,
Dialogue: 0,0:08:36.16,0:08:41.10,CHN,,0,0,0,,
Dialogue: 0,0:08:41.10,0:08:43.16,ENG,,0,0,0,,the different buckets seem pretty spiky?
Dialogue: 0,0:08:41.10,0:08:43.16,CHN,,0,0,0,,
Dialogue: 0,0:08:43.16,0:08:45.82,ENG,,0,0,0,,And you might wonder is it supposed to look that way
Dialogue: 0,0:08:43.16,0:08:45.82,CHN,,0,0,0,,
Dialogue: 0,0:08:45.82,0:08:48.64,ENG,,0,0,0,,or is that just an artifact of the randomness in the simulation,
Dialogue: 0,0:08:45.82,0:08:48.64,CHN,,0,0,0,,
Dialogue: 0,0:08:48.64,0:08:51.16,ENG,,0,0,0,,and if it is, how many samples do we need
Dialogue: 0,0:08:48.64,0:08:51.16,CHN,,0,0,0,,
Dialogue: 0,0:08:51.16,0:08:55.20,ENG,,0,0,0,,before we can be sure that what we're looking at is representative of the true distribution?
Dialogue: 0,0:08:51.16,0:08:55.20,CHN,,0,0,0,,
Dialogue: 0,0:08:59.10,0:09:01.84,ENG,,0,0,0,,Instead moving forward, let's get a little more theoretical
Dialogue: 0,0:08:59.10,0:09:01.84,CHN,,0,0,0,,
Dialogue: 0,0:09:01.84,0:09:05.60,ENG,,0,0,0,,and show the precise shape that these distributions will take on in the long run.
Dialogue: 0,0:09:01.84,0:09:05.60,CHN,,0,0,0,,
Dialogue: 0,0:09:05.60,0:09:09.94,ENG,,0,0,0,,The easiest case to make this calculation is if we have a uniform distribution,
Dialogue: 0,0:09:05.60,0:09:09.94,CHN,,0,0,0,,
Dialogue: 0,0:09:09.94,0:09:13.62,ENG,,0,0,0,,where each possible face of the die has an equal probability, 1/6.
Dialogue: 0,0:09:09.94,0:09:13.62,CHN,,0,0,0,,
Dialogue: 0,0:09:13.62,0:09:17.58,ENG,,0,0,0,,For example, if you then want to know how likely different sums are for a pair of dice,
Dialogue: 0,0:09:13.62,0:09:17.58,CHN,,0,0,0,,
Dialogue: 0,0:09:17.58,0:09:19.40,ENG,,0,0,0,,it's essentially a counting game,
Dialogue: 0,0:09:17.58,0:09:19.40,CHN,,0,0,0,,
Dialogue: 0,0:09:19.40,0:09:23.46,ENG,,0,0,0,,where you count up how many distinct pairs take on the same sum.
Dialogue: 0,0:09:19.40,0:09:23.46,CHN,,0,0,0,,
Dialogue: 0,0:09:23.46,0:09:25.26,ENG,,0,0,0,,Which in the diagram I've drawn,
Dialogue: 0,0:09:23.46,0:09:25.26,CHN,,0,0,0,,
Dialogue: 0,0:09:25.26,0:09:28.62,ENG,,0,0,0,,you can conveniently think about by going through all of the different diagonals.
Dialogue: 0,0:09:25.26,0:09:28.62,CHN,,0,0,0,,
Dialogue: 0,0:09:31.56,0:09:35.22,ENG,,0,0,0,,Since each such pair has an equal chance of showing up, 1 in 36,
Dialogue: 0,0:09:31.56,0:09:35.22,CHN,,0,0,0,,
Dialogue: 0,0:09:35.22,0:09:37.70,ENG,,0,0,0,,all you have to do is count the sizes of these buckets.
Dialogue: 0,0:09:35.22,0:09:37.70,CHN,,0,0,0,,
Dialogue: 0,0:09:37.70,0:09:42.70,ENG,,0,0,0,,That gives us a definitive shape for the distribution describing a sum of two dice
Dialogue: 0,0:09:37.70,0:09:42.70,CHN,,0,0,0,,
Dialogue: 0,0:09:42.70,0:09:45.76,ENG,,0,0,0,,and if we were to play the same game with all possible triplets,
Dialogue: 0,0:09:42.70,0:09:45.76,CHN,,0,0,0,,
Dialogue: 0,0:09:45.76,0:09:48.54,ENG,,0,0,0,,the resulting distribution would look like this.
Dialogue: 0,0:09:45.76,0:09:48.54,CHN,,0,0,0,,
Dialogue: 0,0:09:48.54,0:09:52.10,ENG,,0,0,0,,Now, what's more challenging but a lot more interesting is to ask what happens
Dialogue: 0,0:09:48.54,0:09:52.10,CHN,,0,0,0,,
Dialogue: 0,0:09:52.10,0:09:55.34,ENG,,0,0,0,,if we have a non-uniform distribution for that single die.
Dialogue: 0,0:09:52.10,0:09:55.34,CHN,,0,0,0,,
Dialogue: 0,0:09:55.34,0:09:58.20,ENG,,0,0,0,,We actually talked all about this in the last video.
Dialogue: 0,0:09:55.34,0:09:58.20,CHN,,0,0,0,,
Dialogue: 0,0:09:58.20,0:10:01.22,ENG,,0,0,0,,You do essentially the same thing, you go through all the distinct
Dialogue: 0,0:09:58.20,0:10:01.22,CHN,,0,0,0,,
Dialogue: 0,0:10:01.22,0:10:03.88,ENG,,0,0,0,,pairs of dice which add up to the same value.
Dialogue: 0,0:10:01.22,0:10:03.88,CHN,,0,0,0,,
Dialogue: 0,0:10:03.88,0:10:06.54,ENG,,0,0,0,,It's just that instead of counting those pairs,
Dialogue: 0,0:10:03.88,0:10:06.54,CHN,,0,0,0,,
Dialogue: 0,0:10:06.54,0:10:11.30,ENG,,0,0,0,,for each pair, you multiply the two probabilities of each particular face coming up
Dialogue: 0,0:10:06.54,0:10:11.30,CHN,,0,0,0,,
Dialogue: 0,0:10:11.30,0:10:12.96,ENG,,0,0,0,,and then you add all those together.
Dialogue: 0,0:10:11.30,0:10:12.96,CHN,,0,0,0,,
Dialogue: 0,0:10:12.96,0:10:16.86,ENG,,0,0,0,,The computation that does this for all possible sums has a fancy name,
Dialogue: 0,0:10:12.96,0:10:16.86,CHN,,0,0,0,,
Dialogue: 0,0:10:16.86,0:10:21.62,ENG,,0,0,0,,it's called a Convolution but it's essentially just the weighted version of the counting game
Dialogue: 0,0:10:16.86,0:10:21.62,CHN,,0,0,0,,
Dialogue: 0,0:10:21.62,0:10:24.78,ENG,,0,0,0,,that anyone who's played with a pair of dice already finds familiar.
Dialogue: 0,0:10:21.62,0:10:24.78,CHN,,0,0,0,,
Dialogue: 0,0:10:24.78,0:10:28.78,ENG,,0,0,0,,For our purposes, in this lesson, I'll have the computer calculate all that,
Dialogue: 0,0:10:24.78,0:10:28.78,CHN,,0,0,0,,
Dialogue: 0,0:10:28.78,0:10:32.74,ENG,,0,0,0,,simply display the results for you and invite you to observe certain patterns,
Dialogue: 0,0:10:28.78,0:10:32.74,CHN,,0,0,0,,
Dialogue: 0,0:10:32.74,0:10:34.86,ENG,,0,0,0,,but under the hood, this is what's going on.
Dialogue: 0,0:10:32.74,0:10:34.86,CHN,,0,0,0,,
Dialogue: 0,0:10:36.72,0:10:39.72,ENG,,0,0,0,,So, just to be crystal clear on what's being represented here,
Dialogue: 0,0:10:36.72,0:10:39.72,CHN,,0,0,0,,
Dialogue: 0,0:10:39.72,0:10:43.62,ENG,,0,0,0,,if you imagine sampling two different values from that top distribution,
Dialogue: 0,0:10:39.72,0:10:43.62,CHN,,0,0,0,,
Dialogue: 0,0:10:43.62,0:10:46.68,ENG,,0,0,0,,the one describing a single die and adding them together,
Dialogue: 0,0:10:43.62,0:10:46.68,CHN,,0,0,0,,
Dialogue: 0,0:10:46.68,0:10:52.38,ENG,,0,0,0,,then the second distribution I'm drawing represents how likely you are to see various different sums.
Dialogue: 0,0:10:46.68,0:10:52.38,CHN,,0,0,0,,
Dialogue: 0,0:10:52.38,0:10:58.18,ENG,,0,0,0,,Likewise, if you imagine sampling three distinct values from that top distribution and adding them together,
Dialogue: 0,0:10:52.38,0:10:58.18,CHN,,0,0,0,,
Dialogue: 0,0:10:58.18,0:11:02.40,ENG,,0,0,0,,the next plot represents the probabilities for various different sums in that case.
Dialogue: 0,0:10:58.18,0:11:02.40,CHN,,0,0,0,,
Dialogue: 0,0:11:03.38,0:11:09.06,ENG,,0,0,0,,So, if I compute what the distributions for these sums look like for larger and larger sums,
Dialogue: 0,0:11:03.38,0:11:09.06,CHN,,0,0,0,,
Dialogue: 0,0:11:09.06,0:11:12.60,ENG,,0,0,0,,well, you know what I'm going to say, it looks more and more like a bell curve.
Dialogue: 0,0:11:09.06,0:11:12.60,CHN,,0,0,0,,
Dialogue: 0,0:11:13.20,0:11:16.62,ENG,,0,0,0,,But before we get to that, I want you to make a couple more simple observations.
Dialogue: 0,0:11:13.20,0:11:16.62,CHN,,0,0,0,,
Dialogue: 0,0:11:17.40,0:11:20.46,ENG,,0,0,0,,For example, these distributions seem to be wandering to the right,
Dialogue: 0,0:11:17.40,0:11:20.46,CHN,,0,0,0,,
Dialogue: 0,0:11:20.46,0:11:24.84,ENG,,0,0,0,,and also they seem to be getting more spread out and a little bit more flat.
Dialogue: 0,0:11:20.46,0:11:24.84,CHN,,0,0,0,,
Dialogue: 0,0:11:24.84,0:11:29.98,ENG,,0,0,0,,You cannot describe the central limit theorem quantitatively without taking into account both of those effects,
Dialogue: 0,0:11:24.84,0:11:29.98,CHN,,0,0,0,,
Dialogue: 0,0:11:29.98,0:11:33.50,ENG,,0,0,0,,which in turn requires describing the mean and the standard deviation.
Dialogue: 0,0:11:29.98,0:11:33.50,CHN,,0,0,0,,
Dialogue: 0,0:11:33.50,0:11:35.52,ENG,,0,0,0,,Maybe you're already familiar with those,
Dialogue: 0,0:11:33.50,0:11:35.52,CHN,,0,0,0,,
Dialogue: 0,0:11:35.52,0:11:38.70,ENG,,0,0,0,,but I want to make minimal assumptions here and it never hurts to review.
Dialogue: 0,0:11:35.52,0:11:38.70,CHN,,0,0,0,,
Dialogue: 0,0:11:38.70,0:11:40.68,ENG,,0,0,0,,So let's quickly go over both of those.
Dialogue: 0,0:11:38.70,0:11:40.68,CHN,,0,0,0,,
Dialogue: 0,0:11:43.68,0:11:47.28,ENG,,0,0,0,,The mean of a distribution, often denoted with a Greek letter, mu,
Dialogue: 0,0:11:43.68,0:11:47.28,CHN,,0,0,0,,
Dialogue: 0,0:11:47.28,0:11:50.78,ENG,,0,0,0,,is a way of capturing the center of mass for that distribution.
Dialogue: 0,0:11:47.28,0:11:50.78,CHN,,0,0,0,,
Dialogue: 0,0:11:50.78,0:11:54.74,ENG,,0,0,0,,It's calculated as the expected value of our random variable,
Dialogue: 0,0:11:50.78,0:11:54.74,CHN,,0,0,0,,
Dialogue: 0,0:11:54.74,0:11:58.38,ENG,,0,0,0,,which is a way of saying you go through all of the different possible outcomes
Dialogue: 0,0:11:54.74,0:11:58.38,CHN,,0,0,0,,
Dialogue: 0,0:11:58.38,0:12:02.96,ENG,,0,0,0,,and you multiply the probability of that outcome times the value of the variable.
Dialogue: 0,0:11:58.38,0:12:02.96,CHN,,0,0,0,,
Dialogue: 0,0:12:02.96,0:12:06.54,ENG,,0,0,0,,If higher values are more probable, that weighted sum is going to be bigger,
Dialogue: 0,0:12:02.96,0:12:06.54,CHN,,0,0,0,,
Dialogue: 0,0:12:06.54,0:12:10.08,ENG,,0,0,0,,if lower values are more probable, that weighted time is going to be smaller.
Dialogue: 0,0:12:06.54,0:12:10.08,CHN,,0,0,0,,
Dialogue: 0,0:12:10.62,0:12:14.58,ENG,,0,0,0,,A little more interesting is if you want to measure how spread out this distribution is,
Dialogue: 0,0:12:10.62,0:12:14.58,CHN,,0,0,0,,
Dialogue: 0,0:12:14.58,0:12:16.92,ENG,,0,0,0,,because there's multiple different ways you might do it.
Dialogue: 0,0:12:14.58,0:12:16.92,CHN,,0,0,0,,
Dialogue: 0,0:12:18.72,0:12:20.48,ENG,,0,0,0,,One of them is called the Variance.
Dialogue: 0,0:12:18.72,0:12:20.48,CHN,,0,0,0,,
Dialogue: 0,0:12:20.48,0:12:25.06,ENG,,0,0,0,,The idea there is to look at the difference between each possible value and the mean,
Dialogue: 0,0:12:20.48,0:12:25.06,CHN,,0,0,0,,
Dialogue: 0,0:12:25.06,0:12:28.34,ENG,,0,0,0,,square that difference and ask for its expected value.
Dialogue: 0,0:12:25.06,0:12:28.34,CHN,,0,0,0,,
Dialogue: 0,0:12:28.34,0:12:31.96,ENG,,0,0,0,,The idea is that whether your value is below or above the mean,
Dialogue: 0,0:12:28.34,0:12:31.96,CHN,,0,0,0,,
Dialogue: 0,0:12:31.96,0:12:34.46,ENG,,0,0,0,,when you square that difference you get a positive number
Dialogue: 0,0:12:31.96,0:12:34.46,CHN,,0,0,0,,
Dialogue: 0,0:12:34.46,0:12:36.66,ENG,,0,0,0,,and the larger the difference, the bigger that number.
Dialogue: 0,0:12:34.46,0:12:36.66,CHN,,0,0,0,,
Dialogue: 0,0:12:37.38,0:12:39.24,ENG,,0,0,0,,Squaring it like this turns out to make the math
Dialogue: 0,0:12:37.38,0:12:39.24,CHN,,0,0,0,,
Dialogue: 0,0:12:39.24,0:12:42.16,ENG,,0,0,0,,much, much nicer than if we did something like an absolute value,
Dialogue: 0,0:12:39.24,0:12:42.16,CHN,,0,0,0,,
Dialogue: 0,0:12:42.16,0:12:45.36,ENG,,0,0,0,,but the downside is that it's hard to think about this as a distance
Dialogue: 0,0:12:42.16,0:12:45.36,CHN,,0,0,0,,
Dialogue: 0,0:12:45.36,0:12:48.02,ENG,,0,0,0,,in our diagram because the units are off.
Dialogue: 0,0:12:45.36,0:12:48.02,CHN,,0,0,0,,
Dialogue: 0,0:12:48.02,0:12:50.38,ENG,,0,0,0,,Kind of like the units here are square units
Dialogue: 0,0:12:48.02,0:12:50.38,CHN,,0,0,0,,
Dialogue: 0,0:12:50.38,0:12:53.40,ENG,,0,0,0,,whereas a distance in our diagram would be a kind of linear unit.
Dialogue: 0,0:12:50.38,0:12:53.40,CHN,,0,0,0,,
Dialogue: 0,0:12:53.40,0:12:57.22,ENG,,0,0,0,,So, another way to measure spread is what's called the Standard Deviation,
Dialogue: 0,0:12:53.40,0:12:57.22,CHN,,0,0,0,,
Dialogue: 0,0:12:57.22,0:12:59.32,ENG,,0,0,0,,which is the square root of this value.
Dialogue: 0,0:12:57.22,0:12:59.32,CHN,,0,0,0,,
Dialogue: 0,0:12:59.32,0:13:03.30,ENG,,0,0,0,,That can be interpreted much more reasonably as a distance on our diagram
Dialogue: 0,0:12:59.32,0:13:03.30,CHN,,0,0,0,,
Dialogue: 0,0:13:03.30,0:13:06.04,ENG,,0,0,0,,and it's commonly denoted with the Greek letter Sigma.
Dialogue: 0,0:13:03.30,0:13:06.04,CHN,,0,0,0,,
Dialogue: 0,0:13:06.04,0:13:09.78,ENG,,0,0,0,,So, you know M for mean, as for standard deviation but both in Greek.
Dialogue: 0,0:13:06.04,0:13:09.78,CHN,,0,0,0,,
Dialogue: 0,0:13:11.94,0:13:14.24,ENG,,0,0,0,,Looking back at our sequence of distributions,
Dialogue: 0,0:13:11.94,0:13:14.24,CHN,,0,0,0,,
Dialogue: 0,0:13:14.24,0:13:16.36,ENG,,0,0,0,,let's talk about the mean and standard deviation.
Dialogue: 0,0:13:14.24,0:13:16.36,CHN,,0,0,0,,
Dialogue: 0,0:13:16.36,0:13:19.14,ENG,,0,0,0,,If we call the mean of the initial distribution mu,
Dialogue: 0,0:13:16.36,0:13:19.14,CHN,,0,0,0,,
Dialogue: 0,0:13:19.14,0:13:22.28,ENG,,0,0,0,,which for the one Illustrated happens to be 2.24,
Dialogue: 0,0:13:19.14,0:13:22.28,CHN,,0,0,0,,
Dialogue: 0,0:13:22.28,0:13:26.74,ENG,,0,0,0,,hopefully, it won't be too surprising if I tell you that the mean of the next one is two times mu.
Dialogue: 0,0:13:22.28,0:13:26.74,CHN,,0,0,0,,
Dialogue: 0,0:13:26.74,0:13:30.32,ENG,,0,0,0,,That is, you roll a pair of dice, you want to know the expected value of the sum,
Dialogue: 0,0:13:26.74,0:13:30.32,CHN,,0,0,0,,
Dialogue: 0,0:13:30.32,0:13:32.88,ENG,,0,0,0,,it's two times the expected value for a single die.
Dialogue: 0,0:13:30.32,0:13:32.88,CHN,,0,0,0,,
Dialogue: 0,0:13:33.72,0:13:37.82,ENG,,0,0,0,,Similarly, the expected value for our sum of size 3 is 3 times mu
Dialogue: 0,0:13:33.72,0:13:37.82,CHN,,0,0,0,,
Dialogue: 0,0:13:37.82,0:13:41.64,ENG,,0,0,0,,and so on and so forth. The mean just marches steadily on to the right,
Dialogue: 0,0:13:37.82,0:13:41.64,CHN,,0,0,0,,
Dialogue: 0,0:13:41.64,0:13:45.00,ENG,,0,0,0,,which is why our distributions seem to be drifting off in that direction.
Dialogue: 0,0:13:41.64,0:13:45.00,CHN,,0,0,0,,
Dialogue: 0,0:13:45.00,0:13:50.10,ENG,,0,0,0,,A little more challenging but very important is to describe how the standard deviation changes.
Dialogue: 0,0:13:45.00,0:13:50.10,CHN,,0,0,0,,
Dialogue: 0,0:13:50.10,0:13:53.58,ENG,,0,0,0,,The key fact here is that if you have two different random variables,
Dialogue: 0,0:13:50.10,0:13:53.58,CHN,,0,0,0,,
Dialogue: 0,0:13:53.58,0:13:56.18,ENG,,0,0,0,,then the variance for the sum of those variables
Dialogue: 0,0:13:53.58,0:13:56.18,CHN,,0,0,0,,
Dialogue: 0,0:13:56.18,0:13:59.60,ENG,,0,0,0,,is the same as just adding together the original two variances.
Dialogue: 0,0:13:56.18,0:13:59.60,CHN,,0,0,0,,
Dialogue: 0,0:13:59.60,0:14:03.82,ENG,,0,0,0,,This is one of those facts that you can just compute when you unpack all the definitions.
Dialogue: 0,0:13:59.60,0:14:03.82,CHN,,0,0,0,,
Dialogue: 0,0:14:03.82,0:14:06.38,ENG,,0,0,0,,There are a couple nice intuitions for why it's true.
Dialogue: 0,0:14:03.82,0:14:06.38,CHN,,0,0,0,,
Dialogue: 0,0:14:06.38,0:14:09.90,ENG,,0,0,0,,My tentative plan is to just actually make a series about probability
Dialogue: 0,0:14:06.38,0:14:09.90,CHN,,0,0,0,,
Dialogue: 0,0:14:09.90,0:14:13.64,ENG,,0,0,0,,and talk about things like intuition's underlying variants and its cousins there,
Dialogue: 0,0:14:09.90,0:14:13.64,CHN,,0,0,0,,
Dialogue: 0,0:14:13.64,0:14:16.00,ENG,,0,0,0,,but right now, the main thing I want you to highlight
Dialogue: 0,0:14:13.64,0:14:16.00,CHN,,0,0,0,,
Dialogue: 0,0:14:16.00,0:14:20.28,ENG,,0,0,0,,is how it's the variance that adds, it's not the standard deviation that adds.
Dialogue: 0,0:14:16.00,0:14:20.28,CHN,,0,0,0,,
Dialogue: 0,0:14:20.28,0:14:25.10,ENG,,0,0,0,,So critically, if you were to take 'n' different realizations of the same random variable
Dialogue: 0,0:14:20.28,0:14:25.10,CHN,,0,0,0,,
Dialogue: 0,0:14:25.10,0:14:26.88,ENG,,0,0,0,,and ask what the sum looks like,
Dialogue: 0,0:14:25.10,0:14:26.88,CHN,,0,0,0,,
Dialogue: 0,0:14:26.88,0:14:31.60,ENG,,0,0,0,,the variance of that sum is 'n' times the variance of your original variable,
Dialogue: 0,0:14:26.88,0:14:31.60,CHN,,0,0,0,,
Dialogue: 0,0:14:32.28,0:14:35.22,ENG,,0,0,0,,meaning the standard deviation, the square root of all this,
Dialogue: 0,0:14:32.28,0:14:35.22,CHN,,0,0,0,,
Dialogue: 0,0:14:35.22,0:14:38.42,ENG,,0,0,0,,is the square root of n times the original standard deviation.
Dialogue: 0,0:14:35.22,0:14:38.42,CHN,,0,0,0,,
Dialogue: 0,0:14:39.12,0:14:41.56,ENG,,0,0,0,,For example, back in our sequence of distributions,
Dialogue: 0,0:14:39.12,0:14:41.56,CHN,,0,0,0,,
Dialogue: 0,0:14:41.56,0:14:46.68,ENG,,0,0,0,,if we label the standard deviation of our initial one with Sigma, then the next standard deviation
Dialogue: 0,0:14:41.56,0:14:46.68,CHN,,0,0,0,,
Dialogue: 0,0:14:46.68,0:14:48.98,ENG,,0,0,0,,is going to be the square root of 2 times Sigma, 
Dialogue: 0,0:14:46.68,0:14:48.98,CHN,,0,0,0,,
Dialogue: 0,0:14:48.98,0:14:53.68,ENG,,0,0,0,,and after that, it looks like the square root of 3 times Sigma and so on and so forth.
Dialogue: 0,0:14:48.98,0:14:53.68,CHN,,0,0,0,,
Dialogue: 0,0:14:53.68,0:14:55.84,ENG,,0,0,0,,This like I said is very important.
Dialogue: 0,0:14:53.68,0:14:55.84,CHN,,0,0,0,,
Dialogue: 0,0:14:55.84,0:14:58.94,ENG,,0,0,0,,It means that even though our distributions are getting spread out,
Dialogue: 0,0:14:55.84,0:14:58.94,CHN,,0,0,0,,
Dialogue: 0,0:14:58.94,0:15:00.72,ENG,,0,0,0,,they're not spreading out all that quickly.
Dialogue: 0,0:14:58.94,0:15:00.72,CHN,,0,0,0,,
Dialogue: 0,0:15:00.72,0:15:04.20,ENG,,0,0,0,,They only do so in proportion to the square root of the size of the sum.
Dialogue: 0,0:15:00.72,0:15:04.20,CHN,,0,0,0,,
Dialogue: 0,0:15:04.20,0:15:08.58,ENG,,0,0,0,,As we prepare to make a more quantitative description of the central limit theorem,
Dialogue: 0,0:15:04.20,0:15:08.58,CHN,,0,0,0,,
Dialogue: 0,0:15:08.58,0:15:10.92,ENG,,0,0,0,,the core intuition I want you to keep in your head
Dialogue: 0,0:15:08.58,0:15:10.92,CHN,,0,0,0,,